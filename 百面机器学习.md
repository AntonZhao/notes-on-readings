# 百面机器学习
> [异步社区](https://www.epubit.com/book/detail/7020)
> [douban](https://book.douban.com/subject/30285146/)
> 扎实的数学基础、完整的算法体系、深入的模型理解

![](http://images2.imagebam.com/64/76/3e/d8ed531073921364.jpeg)

## 1 特征工程
> [在线版](https://www.epubit.com/epubit/publish/reader.jsp?id=AF0EBEC9-0E9C-4FB8-9F75-5161D936941E&type=online&bookId=D0641CC9-3540-45F6-9B4B-5F040D99EC70)

特征和数据往往决定了结果的上限。

特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关系。

### 特征归一化（Normalization）

为了消除数据特征之间的量纲影响，**使各指标处于同一数量级**，不同指标之间具有可比性。

常用方法：

 - 线性函数归一化（Min-Max Scaling）：$X_{norm}=\frac{X-X_{min}}{X_{max}-X{min}}$
	 - 将结果映射到[0, 1]范围内，等比缩放
 - 零均值归一化（Z-Score Normalization）：$z=\frac{x-\mu}{\sigma}$（假设原始特征均值为 $\mu$、标准差为 $\sigma$）
	 - 将数据映射到均值为0、标准差为1的分布上

在实际应用中，**通过梯度下降法求解的模型通常需要归一化**，包括线性回归、逻辑回归、支持向量机、神经网络等模型。但对于决策树模型则并不适用。

### 图像数据不足时的处理方法

模型信息来源：

 - 数据集包含的信息
 - 先验信息

先验信息可以作用在模型上，也可作用在数据集上。

 - 基于模型：简化模型、添加正则项、集成学习、Dropout超参数等；
 - 基于数据：数据扩充

其他方法：生成模型（GAN），迁移学习

## 2 模型评估

### 评估指标的局限性

#### 平方根误差的“意外”

如果存在个别偏离程度非常大的离群点（Outlier）时，会让RMSE指标变得很差。

平均绝对百分比误差（Mean Absolute Percent Error，MAPE）：
$$
MAPE=\sum_{i=1}^n |\frac{y_i-\hat y_i}{y_i}| \times \frac{100}{n}
$$
MAPE相当于把每个点的误差进行了归一化。

### 模型评估方法

 - Holdout
 - 交叉验证
	 - k-fold交叉验证：最后用 $k$ 次评估指标的平均值作为最终评估指标
	 - 留一验证
 - 自助法：对总数为 $n$ 的样本集合，进行 $n$ 次有放回的随机抽样，得到大小为 $n$ 的训练集。将最终没被抽出的样本作为验证集（$n$ 无穷大情况下为 $1/e \approx$ 36.8%）。

### 超参数调优

超参数搜索的几个要素：目标函数、搜索范围、算法其他参数（如步长）。

 - 网格搜索：消耗计算资源和时间。快速版：搜索范围&步长先大后小
 - 随机搜索
 - 贝叶斯优化算法：充分利用之前的信息。通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。

[Google Vizier](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/46180.pdf)

### 过拟合与欠拟合

降低“过拟合”风险的方法：

 - 更多的数据
 - 降低模型复杂度
 - 正则化
 - 集成学习：把多个模型集成在一起，降低单一模型过拟合风险

降低“欠拟合”风险的方法：

 - 添加新特征
 - 增加模型复杂度
 - 减小正则项

## 3 经典算法

### SVM

### 逻辑回归

$p=1 /(1+exp(-\theta^Tx))$ 变换得 $\log \frac{p}{1-p}=\theta^Tx$，称几率为 $\frac{p}{1-p}$，对数几率为 $\log \frac{p}{1-p}$。逻辑回归可看作是对于“$y=1|x$”这一事件的对数几率的线性回归。

逻辑回归 vs. 线性回归

 - 不同：分类 vs. 回归
 - 相同：都使用了极大似然估计来对训练样本进行建模；都可以使用梯度下降法求解超参数。


逻辑回归处理多标签分类问题：

 - 一个样本对应一个标签：多项逻辑回归（Softmax Regression），是二分类逻辑回归在多标签分类下的扩展
 - 样本属于多个标签：训练 $k$ 个二分类器，第 $i$ 个分类器用以区分每个样本是否可以归为第 $i$ 类

Softmax Regression：TODO.

### 决策树

## 4 降维

### PCA

### LDA

## 7 优化算法

机器学习算法 = 模型表征 + 模型评估 + 优化算法，优化算法就是在模型表征空间中找到模型评估指标最好的模型。

### 有监督学习的损失函数
> 设 $f$ 为输出，$y$ 为标签

二分类问题：$Y=\{1, -1\}$，我们希望 sign $f(x_i, \theta)=y_i$。（以下都是0-1损失函数的凸上界）

 - Hinge损失：$L(f, y)=max\{0, 1-fy\}$
	 - 在 $fy=1$ 处不可导，因此不能用梯度下降法进行优化，而是用[次梯度下降法](http://www.hanlongfei.com/convex/2015/10/02/cmu-10725-subgradidient/)
 - Logistic损失：$L(f, y)=\log_2(1+exp(-fy))$
	 - 光滑，可用梯度下降法进行优化。因对所有样本点都有所惩罚，故对异常值相对敏感
 - 交叉熵损失：$L(f, y)=-\log_2(\frac{1+fy}{2})$，当 $f\in [-1,1]$时常用
	 - 光滑

回归问题：$Y=\mathbb{R}$，我们希望 $f(x_i, \theta)\approx y_i$

 - 平方损失：$L(f, y)=(f-y)^2$
	 - 光滑，可用梯度下降法进行优化。对异常点比较敏感
 - Huber损失：$L(f, y)=
\begin{cases}
(f-y)^2, &\text{ |f-y| <= σ} \\
2σ|f-y|-σ^2, &\text{|f-y|>σ}
\end{cases}$
	 - 处处可导，对异常点鲁棒

### 机器学习中的优化问题

 - 逻辑回归：凸优化
 - PCA：非凸优化

### 经典优化算法

无约束问题的优化方法：

 - 直接法：直接给出最优解
	 - 需满足两个条件：凸函数、梯度为0有闭式解
 - 迭代法：迭代地修正对最优解的估计
	 - 一阶（梯度下降）法
	 - 二阶（牛顿）法

### 梯度验证

利用求目标函数值的功能，来验证求目标函数梯度的功能是否正确。

### 随机梯度下降法

模型参数更新公式：$\theta_{t+1}=\theta_t-\alpha \nabla L(\theta_t)$

 - 批量梯度下降法（BGD）：所有样本
 - 随机梯度下降法（SGD）：单个样本
 - 小批量梯度下降法（M-BGD）：$m$ 个样本
	 - $m$ 的取值：一般 $m$ 取2得幂次时能充分利用矩阵运算操作
	 - 挑 $m$ 个数据：每次**遍历**前对所有数据进行随机排序，然后在每次**迭代**时顺序挑选 $m$ 个训练数据直至遍历完
	 - 学习率 $\alpha$ 选择：衰减学习速率

### 随机梯度下降法的加速

SGD好比蒙着眼下山。
更新公式：$\theta_{t+1}=\theta_t-\eta g_t$，负梯度表示更新方向，学习速率控制步幅。

方法：惯性保持；环境感知

 - Momentum方法：重利用前一次步伐信息
 - AdaGrad：历史梯度平方和
 - Adam：采用类似滑动窗口内求平均的思想，时间久远的梯度对当前平均值的贡献呈指数衰减
	 - 惯性保持：记录梯度一阶矩（相当于估计 $\mathbb{E}[g_t]$），即过往梯度与当前梯度的平均。
	 - 环境感知：记录梯度二阶矩（相当于估计 $\mathbb{E}[g_t^2]$），即过往梯度平方与当前梯度平方的平均。
	 - 此外还考虑了一阶矩和二阶矩在零初始值情况下的偏置矫正

### L1正则化与稀疏性

希望模型参数具有稀疏性（很多参数为0）的原因：稀疏性过程相当于对模型进行了一次特征选择，只留下一些比较重要的特征，提高模型的泛化能力，降低过拟合的可能。

L1正则化使得模型参数具有稀疏性的原理：

 - 角度1：解空间形状。L1正则项约束的解空间是菱形，L2的是圆形。多边形解空间更易在尖角处与目标函数等高线碰撞，产生稀疏解。
 - 角度2：函数叠加。
 - 角度3：贝叶斯先验。

## 9 前向神经网络

深度前馈网络通常由多个函数复合在一起来表示，该模型与一个DAG相关联，其中图则描述了函数的复合方式。

### DNN中的激活函数

对于DNN，在每一层线性变换后叠加一个非线性激活函数，以避免多层网络等效于单层线性函数，从而获得更强大的学习与拟合能力。

常用激活函数：

 - Sigmoid：$f(z)=\frac{1}{1+exp(-z)}$，导函数为$f'(z)=f(z)(1-f(z))$
 - Tanh：$f(z)=tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}$，导函数为$f'(z)=1-(f(z))^2$
 - ReLU：$f(z)=max(0,z)$，导函数为$f'(z)=\begin{cases}
1, &\text{z>0} \\
0, &\text{z<=0}
\end{cases}$

Sigmoid 和 Tanh会导致梯度消失的原因：导函数在 $z$ 很大或很小时都趋近于0。

ReLU的优点和局限

 - 优点
	 - 计算复杂度小
	 - 非饱和性可以有效解决梯度消失问题
	 - 单侧抑制提供了网络的稀疏表达能力
 - 局限性：负梯度被置0，导致神经元死亡问题。

ReLU变种：[Empirical Evaluation of Rectified Activations in Convolution Network](https://arxiv.org/pdf/1505.00853.pdf)

 - Leaky ReLU：保留很小的负梯度
 - 参数化的ReLU：将负轴部分斜率 $a$ 作为网络中一个可学习参数
 - 随机化ReLU：斜率 $a$ 作为一个满足某种分布的随机采样

### 多层感知机的BP算法

设 $l$ 层的线性变换为 $\bm z^{(l)}=\bm W^{(l)}\bm x^{(l)}+\bm b^{(l)}$，输出为 $\bm a^{(l)}=f(\bm z^{(l)})$，其中 $f$ 为激活函数；$a^{(l)}$ 直接作为下一层的输入，即 $\bm x^{(l+1)}=\bm a^{(l)}$。

梯度下降法中每次迭代对参数 $W$ 和 $b$ 进行更新：
$$
W_{ij}^{(l)}=W_{ij}^{(l)}-\alpha\frac{\partial}{\partial W_{ij}^{(l)}}J(\bm W, \bm b) \tag{9.1}
$$
$$
b_i^{(l)}=b_i^{(l)}-\alpha\frac{\partial}{\partial b_i^{(l)}}J(\bm W, \bm b) \tag{9.2}
$$

计算损失函数对隐含层的偏导：
$$
\frac{\partial}{\partial z_i^{(l)}}J(\bm W, \bm b)=\sum_{j=1}^{s_{l+1}}(\frac{\partial J(\bm W, \bm b)}{\partial z_j^{(l+1)}}\frac{\partial z_j^{(l+1)}}{\partial z_i^{(l)}}) \tag{9.3}
$$
其中 $s_{l+1}$ 为 $l+1$ 层的节点数，而：
$$
\frac{\partial z_j^{(l+1)}}{\partial z_i^{(l)}}=\frac{\partial (W_{ij}^{(l)}x^{(l+1)}+b_j^{(l+1)})}{\partial z_i^{(l)}} \tag{9.4}
$$
其中 $b^{(l+1)}$ 与 $z_i^{(l)}$ 无关可以省去，$x^{(l+1)}=a^{(l)}=f(z^{(l)})$，故（9.4）可写为：
$$
\frac{\partial z_j^{(l+1)}}{\partial z_i^{(l)}}=W_{ij}^{(l)}f'(z_i^{(l)})
$$
$\frac{\partial}{\partial z_i^{(l)}}J(\bm W, \bm b)$ 可以看作损失函数在第 $l$ 层第 $i$ 个节点产生的残差量，记为 $\sigma_i^{(l)}$，故递推公式（9.3）可表示为：
$$
\sigma_i^{(l)}=(\sum_{j=1}^{s_{l+1}}W_{ij}^{(l)}\sigma_j^{(l+1)})f'(z_i^{(l)}) \tag{9.5}
$$

损失对参数函数的梯度可写为：
$$
\frac{\partial}{\partial W_{ij}^{(l)}}J(\bm W, \bm b)=\frac{\partial J(\bm W, \bm b)}{\partial z_j^{(l+1)}}\frac{\partial z_j^{(l+1)}}{\partial W_{ij}^{(l)}}=\sigma_i^{(l+1)}x_j^{(l+1)}=\sigma_i^{(l+1)}a_j^{(l)} \tag{9.6}
$$
$$
\frac{\partial}{\partial b_i^{(l)}}J(W, b)=\sigma_i^{(l+1)} \tag{9.7}
$$

对平方误差损失 $J(\bm W, \bm b)=\frac{1}{2}||y-a^{(L)}||^2=\frac{1}{2}||y-f(z_j^{(L)})||^2$，最后一层的残差：
$$
\sigma^{(L)}=-(y-a^{(L)})f'(z^{(L)}) \tag{9.8}
$$
对交叉熵损失 $J(\bm W, \bm b)=-\sum_{k=1}^n y_k\ln a_k^{(L)}=-\sum_{k=1}^n y_k\ln f(z_k^{(L)})$，在分类问题中，$y_k$ 仅在一个类别 $k$ 时取值为1，其余为0。设实际类别为 $\tilde{k}$，则 $J(\bm W, \bm b)=-\ln a_{\tilde k}^{(L)}$，有：
$$
\sigma^{(L)}=-\frac{f'(z_{\tilde k}^{(L)})}{f(z_{\tilde{k}}^{(L)})} \tag{9.9}
$$
当 $f$ 取 SoftMax 激活函数时，$f'(x)=f(x)(1-f(x))$，有：
$$
\sigma^{(L)}=f(z_k^{(L)})-1=a_{\tilde{k}}^{(L)}-1 \tag{9.10}
$$

不同损失函数的适用场景：

 - 平方误差：更适合输出为**连续**，并且最后一层不含Sigmoid或Softmax激活函数的神经网络。
 - 交叉熵：更适合二分类或多**分类**场景。

### 神经网络训练技巧

权重 $w$ 可初始化为取值范围 $(-\frac{1}{\sqrt{d}}, \frac{1}{\sqrt{d}})$ 的均匀分布，其中 $d$ 是一个神经元接受的输入维度。偏置 $b$ 可设为0。

#### Dropout

Dropout是模型集成方法中最高效与常用的技巧。它以一定的概率 $p$ 临时丢弃一部分节点，作用于每份小批量数据，相当于每次迭代都在训练不同的神经网络，提供了一种轻量级的 Bagging 集成近似。

应用Dropout包括两个阶段：

 - 训练阶段：前向传播、反向传播
 - 预测阶段：前向传播

#### 批量归一化（BN）

BN方法有效规避了复杂超参数对网络训练产生的影响，在加速训练收敛的同时也提升了网络的泛化能力。但同时也降低了模型的拟合能力。

BN针对每一批数据，在网络的每一层输入之前增加归一化处理（均值为0，标准差为1），将所有批数据强制在统一的数据分布下。

恢复原始数据分布：引入变换重构以及可学习参数 $\gamma$ 和 $\beta$（对应输入数据的方差和偏差），可实现与之前网络层参数解耦。

注意CNN由于参数共享机制，每个卷积核的参数在不同位置的神经元当中是共享的，应该被一起归一化。

### CNN

一个CNN模型通常由若干**卷积层**叠加若干**全连接层**组成，中间也包含各种**非线性操作**以及**池化**操作。

卷积运算主要用于处理**类网格结构**的数据。

#### 卷积

 - 稀疏交互：每个输出神经元仅与前一层特定局部区域内的神经元存在连接权重。
	 - 优化过程的时间复杂度减小几个数量级，过拟合得到改善。
	 - 物理意义：先学习局部特征，再将局部特征组合起来形成更复杂和抽象的特征。
 - 参数共享：一个特征映射中的神经元共享参数。是卷积运算的固有属性。
	 - 大大降低了模型的存储需求。
	 - 物理意义：使得卷积层具有平移等变性。

#### 池化

 - 均值池化：对领域内特征数求平均。能够抑制由于领域大小受限造成估计值**方差增大**的现象。对**背景**的保留效果更好。
 - 最大池化：取领域内特征的最大值。能够抑制网络参数误差造成**估计均值偏移**的现象。能更好地提取**纹理**信息。
 - 相邻重叠区域池化：采用比窗口宽度更小的步长，使得窗口在每次滑动时存在重叠区域。
 - 空间金字塔池化：同时计算不同大小的窗口的池化，并将结果拼接在一起作为下一网络层的输入。

池化操作的本质是降采样。池化操作能显著降低参数量，还能保持对平移、伸缩、旋转操作的不变性。

### ResNet

跨层短接，使得训练更深的网络成为可能。

## 14 AI的热门应用

### 计算广告

### 游戏

### 自动驾驶

### 机器翻译

### 人机交互


