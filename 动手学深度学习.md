# 动手学深度学习
> [官网](http://zh.d2l.ai/)

## Notes

### 前言

应用深度学习需要同时理解：

 1. 问题的动机和特点；
 2. 将大量不同类型神经网络层通过特定方式组合在一起的模型背后的数学原理；
 3. 在原始数据上拟合极复杂的深层模型的优化算法；
 4. 有效训练模型、避免数值计算陷阱以及充分利用硬件性能所需的工程技能；
 5. 为解决方案挑选合适的变量（超参数）组合的经验。

### 如何使用

本书将全面介绍深度学习从模型构造到模型训练的方方面面，以及它们在计算机视觉和自然语言处理中的应用。

#### 内容和结构

![](http://zh.d2l.ai/_images/book-org.svg)

如果想短时间了解深度学习最基础的概念和技术，只需阅读第1章至第3章；如果希望掌握现代深度学习技术，还需阅读第4章至第6章。第7章至第10章可以根据兴趣选择阅读。

## 深度学习简介

### 发展

### 特点

表征学习关注如何自动找出表示数据的合适方式。
深度学习是具有多级表示的表征学习方法。它可以逐级表示越来越抽象的概念或模式。

深度学习的一个外在特点是端到端的训练。也就是说，并不是将单独调试的部分拼凑起来组成一个系统，而是将整个系统组建好之后一起训练。

## 预备知识

### 数据操作

`NDArray`提供GPU计算和自动求梯度等更多功能，这些使`NDArray`更加适合深度学习。

#### 运算

矩阵乘法：`dot()`

连结（concatenate）：`concat()`

#### 广播机制

广播（broadcasting）机制：先适当复制元素使这两个`NDArray`形状相同后再按元素运算。

#### 索引

#### 运算的内存开销

如果想避免临时内存开销，可以使用运算符全名函数中的`out`参数。
```python
nd.elemwise_add(X, Y, out=Z)
```

#### `NDArray`和NumPy相互变换

可以通过`array`函数和`asnumpy`函数令数据在`NDArray`和NumPy格式之间相互变换。

### 自动求梯度

`autograd`模块

默认情况下`autograd`会将运行模式从预测模式转为训练模式。

### 查阅文档

`dir`函数：模块里提供了哪些函数和类；
`help`函数：函数或者类的具体用法。

## 深度学习基础

### 线性回归

#### 模型训练

样本、标签、特征

平方损失

解析解（analytical solution）、数值解（numerical solution）

小批量随机梯度下降（mini-batch stochastic gradient descent）
学习率（learning rate）
超参数（hyperparameter）

### softmax回归

#### 交叉熵损失函数

#### 

### 多层感知机

多层感知机（multilayer perceptron，MLP）

#### 激活函数

 - ReLU
 - sigmoid
 - tanh

### 模型选择、欠拟合和过拟合

$K$ 折交叉验证（$K$-fold cross-validation）

### 权重衰减

权重衰减（weight decay）等价于 $L_2$ 范数正则化（regularization）

### dropout

丢弃法有一些不同的变体。本节中提到的丢弃法特指倒置丢弃法（inverted dropout）。

隐藏单元有一定概率被丢弃。设丢弃概率为 $p$， 那么有 $p$ 的概率会被清零，有 $1−p$ 的概率会除以 $1−p$ 做拉伸。

### 正向传播、反向传播和计算图

#### 反向传播

反向传播依据微积分中的链式法则，沿着从输出层到输入层的顺序，依次计算并存储目标函数有关神经网络各层的中间变量以及参数的梯度。

### 数值稳定性和模型初始化

深度模型有关数值稳定性的典型问题是衰减（vanishing）和爆炸（explosion）。

#### 随机初始化模型参数

##### Xavier随机初始化

假设某全连接层的输入个数为 $a$ ，输出个数为 $b$ ，Xavier随机初始化将使该层中权重参数的每个元素都随机采样于均匀分布：
 $$
 U(-\sqrt{\frac{6}{a+b}}, \sqrt{\frac{6}{a+b}})
 $$
它的设计主要考虑到，模型参数初始化后，每层输出的方差不该受该层输入个数影响，且每层梯度的方差也不该受该层输出个数影响。

## 深度学习计算

### 模型构造

可以通过继承`Block`类来构造模型。

### 模型参数的访问、初始化和共享

### 模型参数的延后初始化

### 自定义层

可以通过`Block`类自定义神经网络中的层，从而可以被重复调用。

### 读取和存储

### GPU计算

在默认情况下，MXNet会将数据创建在内存，然后利用CPU来计算。

MXNet要求计算的所有输入数据都在内存或同一块显卡的显存上。这样设计的原因是CPU和不同的GPU之间的数据交互通常比较耗时。因此，MXNet希望用户确切地指明计算的输入数据都在内存或同一块显卡的显存上。

## CNN

### 二维卷积层

本章中介绍的卷积神经网络均使用最常见的二维卷积层。

#### 二维互相关运算

在二维卷积层中，一个二维输入数组和一个二维核（kernel）数组通过互相关运算（cross-correlation）输出一个二维数组。
当卷积窗口滑动到某一位置时，窗口中的输入子数组与核数组**按元素相乘并求和**，得到输出数组中相应位置的元素。

#### 二维卷积层

卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。

#### 互相关运算和卷积运算

卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。

在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。

如无特别说明，本书中提到的卷积运算均指互相关运算。

#### 特征图和感受野

二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素 $x$ 的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做 $x$ 的感受野（receptive field）。

我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。

### 填充和步幅

一般来说，假设输入形状是 $n_h×n_w$ ，卷积核窗口形状是 $k_h×k_w$ ，那么输出形状将会是
$$
(n_h−k_h+1)×(n_w−k_w+1).
$$
所以卷积层的输出形状由输入形状和卷积核窗口形状决定。

#### 填充

填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素）。在很多情况下，我们会设置 $p_h=k_h−1$ 和 $p_w=k_w−1$ 来使输入和输出具有相同的高和宽。这样会方便在构造网络时推测每个层的输出形状。

卷积神经网络经常使用奇数高宽的卷积核，所以两端上的填充个数相等。

#### 步幅

我们将每次滑动的行数和列数称为步幅（stride）。

一般来说，当高上步幅为 $s_h$ ，宽上步幅为 $s_w$ 时，输出形状为
$$
⌊(n_h−k_h+p_h+s_h)/s_h⌋×⌊(n_w−k_w+p_w+s_w)/s_w⌋.
$$

### 多输入通道和多输出通道

前面我们用到的输入和输出都是二维数组，但真实数据的维度经常更高。

通道（channel）维。

#### 多输入通道

当输入数据含多个通道时，我们需要构造一个**输入通道数与输入数据的通道数相同的卷积核**，从而能够与含多通道的输入数据做互相关运算。
设卷积核窗口形状为 $k_h×k_w$ 。当 $c_i=1$ 时，我们知道卷积核只包含一个形状为 $k_h×k_w$ 的二维数组。当 $c_i>1$ 时，我们将会为每个输入通道各分配一个形状为 $k_h×k_w$ 的核数组。把这 $c_i$ 个数组在输入通道维上连结，即得到一个形状为 $c_i×k_h×k_w$ 的卷积核。由于输入和卷积核各有 $c_i$ 个通道，我们可以在各个通道上对输入的二维数组和卷积核的二维核数组做互相关运算，再将这 $c_i$ 个互相关运算的二维输出按通道相加，得到一个二维数组。
这就是含多个通道的输入数据与多输入通道的卷积核做二维互相关运算的输出。

#### 多输出通道

设卷积核输入通道数和输出通道数分别为 $c_i$ 和 $c_o$ ，高和宽分别为 $k_h$ 和 $k_w$ 。如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为 $c_i×k_h×k_w$ 的核数组。将它们在输出通道维上连结，卷积核的形状即 $c_o×c_i×k_h×k_w$ 。在做互相关运算时，每个输出通道上的结果由卷积核在该输出通道上的核数组与整个输入数组计算而来。

#### $1\times 1$ 卷积层

卷积窗口形状为 $1×1$ 的**多通道**卷积层通常称为 $1×1$ 卷积层，其中的卷积运算称为 $1×1$ 卷积。因为使用了最小窗口， $1×1$ 卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能。实际上， $1×1$ 卷积的主要计算发生在通道维上。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么 1×1 卷积层的作用与全连接层等价。

$1×1$ 卷积层通常用来调整网络层之间的通道数，并控制模型复杂度。

### 池化层

池化（pooling）层的提出是为了缓解卷积层对位置的过度敏感性。

#### 二维最大池化层和平均池化层

同卷积层一样，池化层每次对输入数据的一个固定形状窗口（又称池化窗口）中的元素计算输出。池化层直接计算池化窗口内元素的最大值或者平均值。该运算也分别叫做最大池化或平均池化。

#### 填充和步幅

池化层也可以在输入的高和宽两侧的填充并调整窗口的移动步幅来改变输出形状。池化层填充和步幅与卷积层填充和步幅的工作机制一样。

#### 多通道

在处理多通道输入数据时，池化层**对每个输入通道分别池化**，而不是像卷积层那样将各通道的输入按通道相加。这意味着池化层的输出通道数与输入通道数相等。

### 卷积神经网络（LeNet）

### 深度卷积神经网络（AlexNet）

### 使用重复元素的网络（VGG）

### 网络中的网络（NiN）

### 含并行连结的网络（GoogLeNet）

### BN

标准化处理输入数据使各个特征的分布相近：这往往更容易训练出有效的模型。
对深层神经网络来说，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。

在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使整个神经网络在各层的中间输出的数值更稳定。

批量归一化和残差网络为训练和设计深度模型提供了两类重要思路。

#### 对全连接层做批量归一化

通常，我们将批量归一化层置于全连接层中的仿射变换和激活函数之间。

在标准化的基础上，批量归一化层引入了两个可以学习的模型参数，拉伸（scale）参数  $\gamma$  和偏移（shift）参数  $\beta$ 。它们与 $x^{(i)}$ 分别做按元素乘法（符号 $⊙$ ）和加法计算：
$$
y^{(i)}←\gamma ⊙ \hat{x}^{(i)}+\beta.
$$
得到了 $x^{(i)}$ 的批量归一化的输出 $y^{(i)}$ 。

值得注意的是，**可学习的**拉伸和偏移参数保留了不对 $\hat x^{(i)}$ 做批量归一化的可能：如果批量归一化无益，理论上，学出的模型可以不使用批量归一化。

#### 对卷积层做批量归一化

对卷积层来说，批量归一化发生在卷积计算之后、应用激活函数之前。如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且每个通道都拥有独立的拉伸和偏移参数，并均为标量。

#### 预测时的批量归一化

使用批量归一化**训练**时，我们可以将批量大小设得大一点，从而使批量内样本的均值和方差的计算都较为准确。将训练好的模型用于**预测**时，我们希望模型对于任意输入都有确定的输出。因此，单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差。
一种常用的方法是通过移动平均估算整个训练数据集的样本均值和方差，并在预测时使用它们得到确定的输出。

批量归一化层和丢弃层一样，在训练模式和预测模式的计算结果是不一样的。

### 残差网络（ResNet）

### 稠密连接网络（DenseNet）

## RNN

RNN是为更好地处理时序信息而设计的。它引入状态变量来存储过去的信息，并用其与当前的输入共同决定当前的输出。

### 语言模型

自然语言处理中最常见的数据是文本数据。我们可以把一段自然语言文本看作一段离散的时间序列。
给定一个长度为 $T$ 的词的序列 $w_1,w_2,…,w_T$ ，语言模型将计算该序列的概率：
$$
P(w_1,w_2,…,w_T).
$$

#### 语言模型的计算

为了计算语言模型，我们需要计算词的概率，以及一个词在给定前几个词的情况下的条件概率，即语言模型参数。

#### $n$ 元语法

当序列长度增加时，计算和存储多个词共同出现的概率的复杂度会呈指数级增加。

$n$ 阶马尔可夫链（Markov chain of order $n$）指一个词的出现只与前面 $n$ 个词相关。$n$ 元语法通过马尔可夫假设（虽然并不一定成立）简化了语言模型的计算。

### 循环神经网络

RNN并非刚性地记忆所有固定长度的序列，而是通过隐藏状态来存储之前时间步的信息。

#### 含隐藏状态的循环神经网络

隐藏变量能够捕捉截至当前时间步的序列的历史信息，也称为隐藏状态。

RNN模型参数的数量不随时间步的增加而增长。

### 通过时间反向传播

### 门控循环单元（GRU）

### 长短期记忆（LSTM）

### 深度循环神经网络

含有多个隐藏层的循环神经网络，也称作深度循环神经网络。

### 双向循环神经网络

有时候，当前时间步也可能由后面时间步决定。双向循环神经网络通过增加从后往前传递信息的隐藏层来更灵活地处理这类信息。

双向循环神经网络在每个时间步的隐藏状态同时取决于该时间步之前和之后的子序列（包括当前时间步的输入）。

## 优化算法

### 优化与深度学习

### 梯度下降和随机梯度下降

#### 随机梯度下降

在深度学习里，目标函数通常是训练数据集中有关各个样本的损失函数的平均。

设 $n$ 是训练数据样本数，如果使用（批量）梯度下降，每次自变量迭代的计算开销为 $O(n)$ ，它随着 $n$ 线性增长。SGD 使得每次迭代的计算开销从梯度下降的 $O(n)$ 降到了常数 $O(1)$ 。

平均来说，随机梯度是对梯度的一个良好的估计。

### 小批量随机梯度下降

### 动量法

### AdaGrad算法

### RMSProp算法

### AdaDelta算法

### [Adam算法](https://zh.d2l.ai/chapter_optimization/adam.html)

[Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)

## 计算性能

### 命令式和符号式混合编程

开发者们认为，用户应该用纯命令式编程进行开发和调试；当需要产品级别的计算性能和部署时，用户可以将大部分命令式程序转换成符号式程序来运行。Gluon通过提供混合式编程的方式做到了这一点。

通过`HybridSequential`类和`HybridBlock`类构建的模型可以调用`hybridize`函数将命令式程序转成符号式程序。

### 异步计算

只要数据是保存在`NDArray`里并使用MXNet提供的运算符，MXNet将默认使用异步计算来获取高计算性能。

我们可以使用`wait_to_read`函数让前端等待某个的`NDArray`的计算结果完成，再执行前端中后面的语句。或者，我们可以用`waitall`函数令前端等待前面所有计算结果完成。后者是性能测试中常用的方法。

### 自动并行计算

通常，一个运算符会用到所有CPU或单块GPU上全部的计算资源。

MXNet能够通过自动并行计算提升计算性能，例如CPU和GPU的并行计算以及计算和通信的并行。

### 多GPU计算

#### 数据并行

## CV

### 图像增广

### 微调

### 目标检测和边界框

### 锚框

### 多尺度目标检测

### 单发多框检测（SSD）

### 区域卷积神经网络（R-CNN）系列

### 语义分割和数据集

### 全卷积网络（FCN）

### 样式迁移

## NPL

### 词嵌入（word2vec）

### 近似训练

### word2vec的实现

### 子词嵌入（fastText）

### 全局向量的词嵌入（GloVe）

### 求近义词和类比词

### 文本情感分类：使用循环神经网络

### 文本情感分类：使用卷积神经网络（textCNN）

### 编码器—解码器（seq2seq）

### 束搜索

### 注意力机制

### 机器翻译

## 附录

### 数学基础



